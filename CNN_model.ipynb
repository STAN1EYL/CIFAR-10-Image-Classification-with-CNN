{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2TF1iPyQhjc",
        "outputId": "6621dd47-9bb9-498a-b36b-913a007ef9fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0BVeMjZ8s3i",
        "outputId": "0b2aea45-8d28-41fc-85ae-024c851f5063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import json\n",
        "import os\n",
        "\n",
        "\n",
        "train_data = os.path.join(\"/content/drive/MyDrive/cifar-10/train.json\")\n",
        "df = pd.read_json(train_data)\n",
        "train_label = df[\"Label\"].tolist()\n",
        "train_image = df[\"Image\"].tolist()\n",
        "\n",
        "\n",
        "test_data = os.path.join(\"/content/drive/MyDrive/cifar-10/test.json\")\n",
        "df = pd.read_json(test_data)\n",
        "test_image = df[\"Image\"].tolist()\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "\n",
        "# 定義標籤映射\n",
        "label_mapping = {0: 0, 1: 1, 3: 2, 5: 3, 8: 4}\n",
        "\n",
        "# 使用空的 train_y 列表，並逐一映射標籤\n",
        "train_y = []\n",
        "for label in train_label:\n",
        "    mapped_label = label_mapping[label]  # 將標籤映射為新的值\n",
        "    train_y.append(mapped_label)         # 將映射後的標籤加入 train_y 列表\n",
        "\n",
        "\n",
        "train_x = []\n",
        "\n",
        "for dataX in train_image:\n",
        "  dataXs = np.array(dataX, dtype = np.uint8)\n",
        "  dataXs = Image.fromarray(dataXs)\n",
        "  train_x.append(transform(dataXs))\n",
        "\n",
        "\n",
        "#print(train_x)\n",
        "\n",
        "test_x = []\n",
        "\n",
        "for data in test_image:\n",
        "  datas = np.array(data, dtype = np.uint8)\n",
        "  datas = Image.fromarray(datas)\n",
        "  test_x.append(transform(datas))\n",
        "\n",
        "num_workers = 0\n",
        "#batch size\n",
        "batch_size = 20\n",
        "\n",
        "#validation size\n",
        "n_valid = 0.2\n",
        "\n",
        "state = np.random.get_state()\n",
        "np.random.shuffle(train_x)\n",
        "np.random.set_state(state)\n",
        "np.random.shuffle(train_y)\n",
        "\n",
        "train_size = len(train_x)\n",
        "split = int(np.floor(train_size * n_valid))\n",
        "\n",
        "train_x, train_y = train_x[split:], train_y[split:]\n",
        "valid_x, valid_y = train_x[:split], train_y[:split]\n",
        "\n",
        "classes = [\"airplane\", \"car\", \"cat\", \"dog\", \"ship\"]\n",
        "\n",
        "print(train_x)\n",
        "print(type(train_x))"
      ],
      "metadata": {
        "id": "V-_cq7Ce8tX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=2, delta=0):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.best_loss = None\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "\n",
        "        elif val_loss > self.best_loss - self.delta:\n",
        "            self.counter += 1\n",
        "\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(patience=5)\n",
        "\n",
        "class NN_network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NN_network, self).__init__()\n",
        "    #input 3*32*32\n",
        "\n",
        "    # Convolutional layers\n",
        "\n",
        "                #nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding)\n",
        "    self.conv1 = nn.Conv2d(3, 16, 3, padding = 1)\n",
        "    # => 16*32*32 => pool => 16*16*16\n",
        "\n",
        "    self.conv2 = nn.Conv2d(16, 32, 3, padding = 1)\n",
        "    # => 32*16*16 => pool => 32*8*8\n",
        "\n",
        "\n",
        "    # Pooling layer\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    # Linear layer (32*8*8 -> 512)\n",
        "    self.fc1 = nn.Linear(32*8*8, 512)\n",
        "\n",
        "    # Linear layer (512 -> 256)\n",
        "    self.fc2 = nn.Linear(512, 256)\n",
        "\n",
        "    # Linear layer (256 -> 5)\n",
        "    self.fc3 = nn.Linear(256, 5)\n",
        "\n",
        "    # Dropout\n",
        "    self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    # Softmax\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = torch.relu(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = torch.relu(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(-1, 32*8*8)\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = torch.relu(x)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    x = self.fc2(x)\n",
        "    x = torch.relu(x)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    x = self.softmax(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "# 建立模型\n",
        "model = NN_network()\n",
        "print(model)\n",
        "\n",
        "# 創建優化器\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n",
        "\n",
        "# 建立評分標準\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 設定最大世代數\n",
        "max_epoch = 20\n",
        "\n",
        "\n",
        "# 調整 model 至 train 模式\n",
        "model.train()\n",
        "\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "\n",
        "  train_loss_index = 0.0\n",
        "  valid_loss_index = 0.0\n",
        "  for(input, label) in zip(train_x, train_y):\n",
        "\n",
        "    label = torch.tensor(label, dtype = torch.long).unsqueeze(0)\n",
        "    input = torch.unsqueeze(input, 0)\n",
        "\n",
        "    optimizer.zero_grad()      # 將梯度歸零\n",
        "\n",
        "    y_pred = model(input)\n",
        "\n",
        "    loss = criterion(y_pred, label)\n",
        "\n",
        "    loss.backward()         # 透過 backward 取得每個參數的梯度值\n",
        "    optimizer.step()         # 透過梯度下降執行下一步的參數更新\n",
        "\n",
        "    train_loss_index += loss.item()*input.size(0)\n",
        "\n",
        "  model.eval()\n",
        "  for (input, label) in zip(valid_x, valid_y):\n",
        "    label = torch.tensor(label, dtype = torch.long).unsqueeze(0)\n",
        "    input = torch.unsqueeze(input, 0)\n",
        "\n",
        "    y_pred = model(input)\n",
        "\n",
        "    loss = criterion(y_pred, label)\n",
        "\n",
        "    valid_loss_index += loss.item()*input.size(0)\n",
        "\n",
        "  train_loss_index = train_loss_index/len(train_x)\n",
        "  valid_loss_index = valid_loss_index/len(valid_x)\n",
        "\n",
        "  train_loss.append(train_loss_index)\n",
        "  valid_loss.append(valid_loss_index)\n",
        "\n",
        "  if not (epoch + 1) % 1:\n",
        "    print(f'Epoch: {epoch+1} \\tTraining Loss: {train_loss_index} \\tValidation Loss: {valid_loss_index}')\n",
        "    #print(f'epoch: {epoch+1}, loss: {loss.item()}')\n",
        "\n",
        "  early_stopping(valid_loss_index)\n",
        "  if early_stopping.early_stop:\n",
        "      print(\"Early stopping triggered.\")\n",
        "      break\n",
        "print(model)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAtoTuRjtYgV",
        "outputId": "d1706a51-e92d-4c5f-b43d-f4e80c4b8d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN_network(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=5, bias=True)\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            ")\n",
            "Epoch: 1 \tTraining Loss: 1.1838756848865597 \tValidation Loss: 0.8635313077243045\n",
            "Epoch: 2 \tTraining Loss: 0.8413447286952049 \tValidation Loss: 0.665833334524541\n",
            "Epoch: 3 \tTraining Loss: 0.6595656018381674 \tValidation Loss: 0.6259807572733361\n",
            "Epoch: 4 \tTraining Loss: 0.5152331858654929 \tValidation Loss: 0.5926325302633351\n",
            "Epoch: 5 \tTraining Loss: 0.4206233589992961 \tValidation Loss: 0.42469300451327774\n",
            "Epoch: 6 \tTraining Loss: 0.32563536805203636 \tValidation Loss: 0.3949077255927687\n",
            "Epoch: 7 \tTraining Loss: 0.27282822029556936 \tValidation Loss: 0.32890402242488426\n",
            "Epoch: 8 \tTraining Loss: 0.2321779314555672 \tValidation Loss: 0.3422319079856618\n",
            "Epoch: 9 \tTraining Loss: 0.18835441825709093 \tValidation Loss: 0.33008618962147096\n",
            "Epoch: 10 \tTraining Loss: 0.14801792673527436 \tValidation Loss: 0.1929021975392755\n",
            "Epoch: 11 \tTraining Loss: 0.14439085943859922 \tValidation Loss: 0.23355262704200222\n",
            "Epoch: 12 \tTraining Loss: 0.12538585899271315 \tValidation Loss: 0.26854539806073485\n",
            "Epoch: 13 \tTraining Loss: 0.10681777358525073 \tValidation Loss: 0.21642758358725986\n",
            "Epoch: 14 \tTraining Loss: 0.11015482646829461 \tValidation Loss: 0.13464699992589457\n",
            "Epoch: 15 \tTraining Loss: 0.09620024157523924 \tValidation Loss: 0.07910096716162726\n",
            "Epoch: 16 \tTraining Loss: 0.07816382416700239 \tValidation Loss: 0.08112904173203829\n",
            "Epoch: 17 \tTraining Loss: 0.06119120193222202 \tValidation Loss: 0.17324397994059565\n",
            "Epoch: 18 \tTraining Loss: 0.07270377959572281 \tValidation Loss: 0.0512277677714315\n",
            "Epoch: 19 \tTraining Loss: 0.04989370130196614 \tValidation Loss: 0.08632495703479624\n",
            "Epoch: 20 \tTraining Loss: 0.05061171400743911 \tValidation Loss: 0.07958126134523676\n",
            "NN_network(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=5, bias=True)\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=2, delta=0):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.best_loss = None\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "\n",
        "        elif val_loss > self.best_loss - self.delta:\n",
        "            self.counter += 1\n",
        "\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(patience=5)\n",
        "\n",
        "class NN_network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NN_network, self).__init__()\n",
        "    #input 3*32*32\n",
        "\n",
        "    # Convolutional layers\n",
        "\n",
        "                #nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding)\n",
        "    self.conv1 = nn.Conv2d(3, 16, 3, padding = 1)\n",
        "    # => 16*32*32 => pool => 16*16*16\n",
        "\n",
        "    self.conv2 = nn.Conv2d(16, 32, 3, padding = 1)\n",
        "    # => 32*16*16 => pool => 32*8*8\n",
        "\n",
        "\n",
        "    # Pooling layer\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    # Linear layer (32*8*8 -> 512)\n",
        "    self.fc1 = nn.Linear(32*8*8, 512)\n",
        "\n",
        "    # Linear layer (512 -> 256)\n",
        "    self.fc2 = nn.Linear(512, 256)\n",
        "\n",
        "    # Linear layer (256 -> 5)\n",
        "    self.fc3 = nn.Linear(256, 5)\n",
        "\n",
        "    # Dropout\n",
        "    self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    # Softmax\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = torch.relu(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = torch.relu(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(-1, 32*8*8)\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = torch.relu(x)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    x = self.fc2(x)\n",
        "    x = torch.relu(x)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    x = self.softmax(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "# 建立模型\n",
        "model = NN_network()\n",
        "print(model)\n",
        "\n",
        "# 創建優化器\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n",
        "\n",
        "# 建立評分標準\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 設定最大世代數\n",
        "max_epoch = 20\n",
        "\n",
        "\n",
        "# 調整 model 至 train 模式\n",
        "model.train()\n",
        "\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "class_correct = list(0. for i in range(5))\n",
        "class_total = list(0. for i in range(5))\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "\n",
        "  train_loss_index = 0.0\n",
        "  valid_loss_index = 0.0\n",
        "  for(input, label) in zip(train_x, train_y):\n",
        "\n",
        "    label = torch.tensor(label, dtype = torch.long).unsqueeze(0)\n",
        "    input = torch.unsqueeze(input, 0)\n",
        "\n",
        "    optimizer.zero_grad()      # 將梯度歸零\n",
        "\n",
        "    y_pred = model(input)\n",
        "\n",
        "    loss = criterion(y_pred, label)\n",
        "\n",
        "    loss.backward()         # 透過 backward 取得每個參數的梯度值\n",
        "    optimizer.step()         # 透過梯度下降執行下一步的參數更新\n",
        "\n",
        "    train_loss_index += loss.item()*input.size(0)\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  def accuracy(x, y):\n",
        "    for input, label in zip(x, y)                           # 遍歷所有資料\n",
        "\n",
        "      output = model(input)\n",
        "\n",
        "      _, pred = torch.max(output, 1)\n",
        "\n",
        "      correct_tensor = pred.eq(label.data.view_as(pred))\n",
        "      correct = np.squeeze(correct_tensor.numpy())\n",
        "\n",
        "      for i in range(batch_size):\n",
        "          labels = label.data[i]\n",
        "          class_correct[labels] += correct[i].item()\n",
        "          class_total[labels] += 1                                  # 即預測正確correct累加\n",
        "\n",
        "\n",
        "    for i in range(5):\n",
        "      if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "      else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "    print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "        100. * np.sum(class_correct) / np.sum(class_total),\n",
        "        np.sum(class_correct), np.sum(class_total)))\n",
        "\n",
        "    return np.sum(class_correct) / np.sum(class_total)                            # 計算準確率\n",
        "\n",
        "\n",
        "  train_accuracy.append(accuracy(train_x, train_y))   # 續練資料帶入 ， (*100)是將結果轉成百分比的形式\n",
        "  val_accuracy.append(accuracy(valid_x, valid_y))         # 驗證資料帶入 ， (*100)是將結果轉成百分比的形式\n",
        "\n",
        "\n",
        "  for (input, label) in zip(valid_x, valid_y):\n",
        "    label = torch.tensor(label, dtype = torch.long).unsqueeze(0)\n",
        "    input = torch.unsqueeze(input, 0)\n",
        "\n",
        "    y_pred = model(input)\n",
        "\n",
        "    loss = criterion(y_pred, label)\n",
        "\n",
        "    valid_loss_index += loss.item()*input.size(0)\n",
        "\n",
        "  train_loss_index = train_loss_index/len(train_x)\n",
        "  valid_loss_index = valid_loss_index/len(valid_x)\n",
        "\n",
        "  train_loss.append(train_loss_index)\n",
        "  valid_loss.append(valid_loss_index)\n",
        "\n",
        "  if not (epoch + 1) % 1:\n",
        "    print(f'Epoch: {epoch+1} \\tTraining Loss: {train_loss_index} \\tValidation Loss: {valid_loss_index}')\n",
        "    #print(f'epoch: {epoch+1}, loss: {loss.item()}')\n",
        "\n",
        "  early_stopping(valid_loss_index)\n",
        "  if early_stopping.early_stop:\n",
        "      print(\"Early stopping triggered.\")\n",
        "      break\n",
        "print(model)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lHgcfVQwFpha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# track test loss\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "model.eval()\n",
        "# iterate over test data\n",
        "for input, label in test_loader:\n",
        "\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model(input)\n",
        "\n",
        "    _, pred = torch.max(output, 1)\n",
        "\n",
        "    correct_tensor = pred.eq(label.data.view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy())\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        labels = label.data[i]\n",
        "        class_correct[labels] += correct[i].item()\n",
        "        class_total[labels] += 1\n",
        "\n",
        "# average test loss\n",
        "test_loss = test_loss/len(test_x)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "metadata": {
        "id": "7TWOOFoTq5wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# track test loss\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "model.eval()\n",
        "# iterate over test data\n",
        "\n",
        "def accuracy(images, labels):\n",
        "    correct = 0\n",
        "    for i in range(len(images)):                            # 遍歷所有資料\n",
        "\n",
        "        images[i].reshape(784, 1)                           # 將images轉為列向量\n",
        "\n",
        "        w = np.dot(w1, images[i]) + b1                      # w = Wx + b\n",
        "       ly = Softmax(w)                                     # 計算Softmax\n",
        "\n",
        "        a = np.argmax(ly)                                   # 取ly([x], [x], [x])中最大值的位置(索引)\n",
        "\n",
        "        true = np.argmax(labels[i])                         # labels[x, x, x]中最大值的位置(索引)\n",
        "\n",
        "        if (a == true):                                     # 如果兩者最大值位置相同\n",
        "            correct += 1                                    # 即預測正確correct累加\n",
        "\n",
        "    return correct / len(images)                            # 計算準確率\n",
        "\n",
        "train_accuracy = accuracy(train_image, train_label) * 100   # 續練資料帶入 ， (*100)是將結果轉成百分比的形式\n",
        "val_accuracy = accuracy(val_image, val_label) * 100         # 驗證資料帶入 ， (*100)是將結果轉成百分比的形式\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for input, label in test_loader:\n",
        "\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model(input)\n",
        "\n",
        "    _, pred = torch.max(output, 1)\n",
        "\n",
        "    correct_tensor = pred.eq(label.data.view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy())\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        labels = label.data[i]\n",
        "        class_correct[labels] += correct[i].item()\n",
        "        class_total[labels] += 1\n",
        "\n",
        "# average test loss\n",
        "test_loss = test_loss/len(test_x)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "metadata": {
        "id": "qFYDYycY-I_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('123.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzqSwojW-pvL",
        "outputId": "dde1d0ec-fe5c-41c6-b161-fe825149b94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    1\n",
            "Name: Label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import json\n",
        "import os\n",
        "\n",
        "data = os.path.join(\"/content/drive/MyDrive/cifar-10/train.json\")\n",
        "df = pd.read_json(data)\n",
        "label = df[\"Label\"]\n",
        "image = df[\"Image\"].tolist()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "y = label\n",
        "x = []\n",
        "\n",
        "for data in image:\n",
        "  datas = np.array(data, dtype = np.uint8)\n",
        "  datas = Image.fromarray(datas)\n",
        "  x.append(transform(datas))\n",
        "\n",
        "\n",
        "print(x)\n",
        "print(type(x))"
      ],
      "metadata": {
        "id": "6ugrltUbSXMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "import json\n",
        "import os\n",
        "\n",
        "data = os.path.join(\"/content/123.json\")\n",
        "df = pd.read_json(data)\n",
        "label = df[\"Label\"]\n",
        "image = df[\"Image\"].tolist()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean = [0.5, 0.5, 0.5],std = [0.5, 0.5, 0.5])\n",
        "])\n",
        "imgs = []\n",
        "\n",
        "for a in image:\n",
        "  aa = np.array(a, dtype = np.uint8)\n",
        "  aa = Image.fromarray(aa)\n",
        "  img = transform(aa)\n",
        "  imgs.append(img)\n",
        "\n",
        "  out_image = to_pil_image(img)\n",
        "  out_path = os.path.join(\"/content/123.png\")\n",
        "  out_image.save(out_path)\n",
        "  print(f\"Saved image: {out_path}\")\n",
        "\n",
        "#print(f\"Processed {len(imgs)} images and saved them.\")\n",
        "print(imgs)\n",
        "print(type(imgs))"
      ],
      "metadata": {
        "id": "tbWz78mxSaVF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}